\documentclass{beamer}
\usepackage{graphicx}

\usetheme{simple}

\usepackage{lmodern}
\usepackage[scale=2]{ccicons}

% TODO: 
%   position adjustement
%   change colours
%       

% Watermark background (simple theme)

% \setwatermark{\includegraphics[height=8cm]{img/uwat.jpg}}
\setwatermark{\fontsize{125pt}{125pt}\selectfont{Overfit}}


\newcommand{\heart}{\ensuremath\heartsuit}

\title{Melbourne University AES/MathWorks/NIH Seizure Prediction}
\subtitle{}
\date{\today}
\author{Shivam Kalra \& Ruifan Yu \\ \texttt{\{shivam.kalra,ruifan.yu\}@uwaterloo.ca}}

\institute{}

\begin{document}

\maketitle

\begin{frame}{Problem Description}
  \framesubtitle{Introduction}

  \begin{itemize}
  \item
    Nearly one-third of patients with epilepsy continue to have \textbf{seizures} despite
    optimal medication management \cite{ramgopal_seizure_2014}.

  \item
    Seizures are a symptom associated with abnormal electrical activity in the
    brain.

  \item
    \alert{What is a seizure?} and \alert{When to detect it?} questions remain
    elusive.

  \item
    Plenty data is available, \textbf{machine learning} can help in building
    seizure forecasting systems.

  \item
     \textbf{Could save life!}
    
  \end{itemize}

\end{frame}

\begin{frame}{Problem Description}
  \framesubtitle{Melbourne University AES/MathWorks/NIH Seizure Prediction}
  \begin{block}{What is given and what is required?}
    \begin{itemize}
    \item
      Human brain activity (intracranial EEG) taken from multiple sensors on
      brain.

    \item
      Each recording is \textbf{10 minutes} long, recorded at \textbf{400 Hz}
      resulting $\boldsymbol{240,000}$ data points per recording.

    \item
      Challenge is to classify unseen recording as \textbf{Preictal}
      (prior to seizure) or \textbf{Interictal} (at least an hour before
      seizure).
    \end{itemize}
  \end{block}
    
\end{frame}

\begin{frame}{Problem Description}
  \framesubtitle{Tell me if this is Interictal or Preictal?}
  \begin{columns}
    \column{0.5\textwidth}
    \hspace*{-0.9cm}
    \includegraphics[scale=0.25]{img/all_data.eps}
    \column{0.4\textwidth}
    \begin{block}{Input}
      Figure shows \textbf{one sample of input data} from Patient 1's data-set.
      Shape of the data is $16 \times 240000$.
    \end{block}

    \begin{block}{Output}
      Classifier model needs to figure out if it is \textbf{Preictal} or
      \textbf{Interictal}.
    \end{block}

  \end{columns}
\end{frame}

\begin{frame}{Problem Description}
  \framesubtitle{Red is Preictal. But predicting this is not very trivial...}
  
  \begin{columns}
    \column{0.4\textwidth}
    \includegraphics[scale=0.23]{img/iex.eps}
    \column{0.5\textwidth}
    \includegraphics[scale=0.23]{img/pex.eps}

  \end{columns}
\end{frame}


\begin{frame}{Problem Description}
  \framesubtitle{How good is raw data?? TSNE visualization for Patient 1 Channel 3.}
  \begin{center}
    \vspace*{-0.5cm}
    \includegraphics[scale=0.32]{img/tsne_raw_data.eps}
  \end{center}
\end{frame}

\begin{frame}{Problem Description}
  \framesubtitle{Okay, so prediction is hard on raw data..but we got more issues!!!}

  \begin{columns}
    \column{0.35\textwidth}
    \includegraphics[scale=0.38]{img/serious.jpg}
    \column{0.45\textwidth}
    \begin{block}{}
      Apart from being already difficult prediction problem, we got bigger
      issues with data-set. \textbf{This is not cool!!}
    \end{block}
  \end{columns}
\end{frame}


\begin{frame}{Problems with Data Set}
  \framesubtitle{There are only two types of people in the world, those who can
    extrapolate from incomplete data...}

  \begin{columns}
    
    \column{0.5\textwidth}
      % \includegraphics[scale=0.43]{img/baddata.jpg}
      \includegraphics[scale=0.35]{img/data_problems.png}

    \column{0.4\textwidth}

    \begin{block}{Training Data-set has...}
      \begin{enumerate}
      \item Categorical Imbalance
      \item Missing Data or Random Dropouts
      \end{enumerate}
    \end{block}

  \end{columns}
  
\end{frame}

\begin{frame}{Problems with Data Set}
  \framesubtitle{Categorical Imbalance}

  \begin{center}
    \includegraphics[scale=0.28]{img/cat_imbalance.eps}
  \end{center}
\end{frame}


\begin{frame}{Problems with Data Set}
  \framesubtitle{Missing/Dropouts in Data Set}

  \begin{block}{}
    \begin{itemize}
    \item Random dropouts of \textbf{10 seconds or more} in the EEG signals across all the 16 channels.
    \item Exist in \textbf{abundance} (even in testing data set).
    \item Some training data is \textbf{entirely empty} (completely missing!!!)
    \end{itemize}
  \end{block}

  \begin{columns}
    \column{0.55\textwidth}
    \includegraphics[scale=0.13]{img/data_drops2.eps}

    \column{0.37\textwidth}
    \textbf{Figure: Missing data in channel 1 and 3 from Patient 1's data set}
  \end{columns}
\end{frame}
 
% \begin{frame}{Classification}
%   \framesubtitle{Ingredients of our present classifier...}

%   \textbf{Ensemble} of 3 different classifier models:
  
%   \begin{enumerate}
%   \item \textbf{SVM/RF/GB} classification using various \textbf{DSP features}
%   \item \textbf{Deep Learning:} CNN classification of Spectrograms
%   \item SVM classification on \textbf{Radon Transforms} of Spectrograms
%   \end{enumerate}

% \end{frame}


\begin{frame}{Model 1: SVM/RF/GB classification using various DSP features}
  \framesubtitle{Features Extraction: Frequency Bands}

  Frequency bands are chosen as in~\cite{korshunova_faculty_2015}.
  
  \begin{block}{}
    \begin{table}[]
      \centering
      \caption{Frequency bands in Spectrograms}
      \begin{tabular}{ll}
        \textbf{Name}               & \textbf{Frequency Range (Hz)} \\
        \textbf{Delta}     & 0.4 -- 4                      \\
        \textbf{Theta}     & 4 -- 8                        \\
        \textbf{Alpha}     & 8 -- 12                       \\
        \textbf{Beta}      & 12 -- 30                      \\
        \textbf{Lowgamma}  & 30 -- 80                      \\
        \textbf{Highgamma} & 80 -- 180                    
      \end{tabular}
    \end{table}
  \end{block}

\end{frame}

\begin{frame}{Model 1: SVM/RF/GB classification using various DSP features}
  \framesubtitle{Features Extraction: Frequency Domain}

  Each feature is extracted from window of 20 seconds for a given input EEG
  wave.
  
  \begin{block}{Frequency Domain}
    \begin{itemize}
    \item Extracted magnitudes of \textbf{FFT} in each frequency band.
    \item \textbf{Total Features}: $16 \times 6 = 96$
    \end{itemize}
  \end{block}
  
  \begin{center}
    \includegraphics[scale=0.25]{img/fft.png}
  \end{center}
    
\end{frame}


\begin{frame}{Model 1: SVM/RF/GB classification using various DSP features}
  \framesubtitle{Features Extraction: Time Domain}

  \begin{block}{Time Domain}
    \begin{itemize}
    \item Extracted energy by \textbf{Butterworth Band pass Filter} within each
      frequency band.
    \item \textbf{Total Features}: $16 \times 6 = 96$
    \end{itemize}
    
  \end{block}
  
\end{frame}

 
\begin{frame}{Model 1: SVM/RF/GB classification using various DSP features}
  \framesubtitle{Features Extraction: Correlation}
 
  \begin{block}{Correlation Features}
    \begin{itemize}

    \item Calculated correlation between pair of channels.
    \item \textbf{Total Features}: $\frac{(16 - 1) \times 16}{2} = 120$
 
    \end{itemize}

  \end{block}

  \begin{columns}
    \column{0.45\textwidth}
    \includegraphics[scale=0.22]{img/corr1.png}
    \column{0.5\textwidth}
    \includegraphics[scale=0.22]{img/corr2.png}
  \end{columns}
\end{frame}

\begin{frame}{Model 1: SVM/RF/GB classification using various DSP features}
  \framesubtitle{TSNE Visualization of all features combined ($120+96+96 = 312$)}

  \begin{center}
    \vspace*{-0.15cm}
  \includegraphics[scale=0.35]{img/trad_feat_viz.eps}
  \end{center}

\end{frame}

\begin{frame}{Model 1: Feature Extraction Summarized...}

  \begin{center}
  \includegraphics[scale=0.3]{img/model.png}
  \end{center}

\end{frame}

\begin{frame}{Model 1: Final Prediction}
  \framesubtitle{}
  \begin{center}
  \includegraphics[scale=0.2]{img/window.png}
  \end{center}
\end{frame}

\begin{frame}{Model 1: Experiences with SVM...}
  \framesubtitle{}
  \begin{columns}
    \column{0.4\textwidth}
    \includegraphics[scale=0.3]{img/coaram.png}
    \column{0.45\textwidth}
    \begin{itemize}
      \item \textbf{Unbalanced labels:} Set \texttt{class\_weight} to \texttt{balanced} in
        Scikit-Learn library.
      \item Big \texttt{C} brings penalty on mis-classified observations

      \item Big \texttt{gamma} gives us more flexible decision boundary, but very
          likely to over-fit.
    \end{itemize}
  \end{columns}
\end{frame}


\begin{frame}{Model 1: Experiences with Gradient Boost...}
  \framesubtitle{}

  \begin{block}{Handle Imbalanced Dataset}
    \begin{itemize}
    \item Balance the positive and negative weights, via \texttt{scale\_pos\_weight}.
    \end{itemize}
  \end{block}


  \begin{block}{Control Over-fitting}
    \begin{itemize}
    \item Control model complexity set \texttt{max\_depth}, \texttt{min\_child\_weight} and \texttt{gamma}.
    \item Add randomness to make training robust to noise, set sub-sample ratio.
    \item Set early stop round and limit the \texttt{max\_depth} to avoid over-fitting.
    \end{itemize}
  \end{block}

\end{frame}


\begin{frame}{Model 1: Unreal AUC in Training Data}

  \begin{columns}
    \column{0.32\textwidth}
    \includegraphics[scale=0.25]{img/roccurve.png}
    \column{0.27\textwidth}
    \includegraphics[scale=0.25]{img/confmatrix.png}
    \column{0.4\textwidth}
    \begin{itemize}
    \item This is caused by shuffling the train test data-set.
    \item Shuffling causes data leakage in the validation set.
    \item There should not be overlapping between train and test set.
    \item This will lead to a higher CV score during training (manually separate the train test set)
 
    \end{itemize}

    
  \end{columns}

\end{frame}

\begin{frame}{Model 2: Deep Learning (CNN) on Spectrograms}
  \framesubtitle{}
  \begin{columns}
    \column{0.38\textwidth}
  \includegraphics[scale=0.27]{img/deep.png}
    \column{0.55\textwidth}
    \includegraphics[scale=0.18]{img/deeper.jpg}
  \end{columns}
\end{frame}


\begin{frame}{Model 2: Deep Learning (CNN) on Spectrograms}
  \framesubtitle{Some background research...}

  \begin{block}{Why Convolution Neural Networks?}
    \begin{itemize}
    \item Our \textbf{eternal love} for deep learning...
    \item Successful results by CNN in seizure detection as in
      ~\cite{korshunova_faculty_2015,mirowski2008comparing}.
    \item Iryna Korshunova's CNN approach in~\cite{korshunova_faculty_2015}
      topped among best $10\%$ in 2014's seizure prediction competition.
    \end{itemize}
  \end{block}

\end{frame}


% \begin{frame}{Model 2: Deep Learning (CNN) on Spectrograms}
%   \framesubtitle{Someone on Kaggle is doing good with Deep Learning..it seems..}
  
%   \begin{block}{\texttt{deepfit}..who are they? Sounds deep learn*ish*!!}
%     \includegraphics[scale=0.3]{img/who_are_they.png}
%   \end{block}


%   \begin{itemize}
%   \item This is some \textbf{random team on leader board} (not from this class most likely??).
%   \item Another motivation to pursue \textbf{deep learning}.
%     \pause
%   \item \textbf{However, they may not be using deep learning..we don't know yet!!}

%   \end{itemize}

% \end{frame}

\begin{frame}{Model 2: Deep Learning (CNN) on Spectrograms}
  \framesubtitle{Input/Output for training the CNN...}

  \begin{block}{Preprocessing}
    All the \textbf{unsafe} data points are removed as per guideline of
    competition.
  \end{block}
  
  \begin{block}{Input}
    \begin{itemize}
    \item Raw wave data is converted into \textbf{Spectrograms}.
    \item \textbf{Frequencies} are binned into \textbf{6 bands}.
    \item \textbf{Time domain} is binned with windows of \textbf{10 seconds} each.
    \end{itemize}
  \end{block}  

  \begin{block}{Output}
    \begin{itemize}
      \item Interictal $[1, 0]$
      \item or, Preictal   $[0, 1]$
    \end{itemize}
  \end{block}  

\end{frame}

\begin{frame}{Model 2: Deep Learning (CNN) on Spectrograms}
  \framesubtitle{Final Spectrogram as Input to CNN}

  Final Spectrogram becomes: $16 \times 6 \times 10$. \textbf{Right is Preictal,
    can you guess? Well, lets leave it to CNN to classify!}

  \begin{columns}
    \column{0.5\textwidth}
    \includegraphics[scale=0.22]{img/sample_spec.eps}
    
    \column{0.5\textwidth}

    \includegraphics[scale=0.22]{img/sample_p_spec.eps}
  \end{columns}

\end{frame}


\begin{frame}{Model 2: Deep Learning (CNN) on Spectrograms}
  \framesubtitle{What is convolution?}

  \begin{columns}
    \column{0.48\textwidth}
    \begin{block}{Convolution Operator}
      \begin{align*}
        (f * g)(t) &= \int_{-\infty}^{\infty}f(\tau) g(t - \tau) d\tau
      \end{align*}
    \end{block}
    \column{0.45\textwidth}
    \begin{itemize}
    \item Can be generalized to $n$ dimensions.
    \item Fast to calculate.
    \item Very important concept in discrete numerical analysis.
    \end{itemize}
  \end{columns}
\end{frame}

\begin{frame}{Model 2: Deep Learning (CNN) on Spectrograms}
  \framesubtitle{Example of Convolution in Image Processing}

  \begin{center}
  \includegraphics[scale=0.26]{img/mahal_conv.png}

  Ref: https://flexmonkey.blogspot.ca/2015/05/convolution-filters-in-swift-with.html
  \end{center}
\end{frame}



\begin{frame}{Model 2: Deep Learning (CNN) on Spectrograms}
  \framesubtitle{Overview of Convolution Neural Network (CNN)}

  \begin{block}{}
    \begin{itemize}
    \item Learns \textbf{Convolution Kernels} (more native to image operations).
    \item Apply \textbf{Pooling} to reduce dimension.
    \item Perform classification using \textbf{Dense} layers.
    \end{itemize}
  \end{block}
  
  \begin{center}
    \includegraphics[scale=0.15]{img/cnn_gen.jpg}

    Ref: \texttt{https://culurciello.github.io/assets/nets/lenet5.jpg}
  \end{center}

\end{frame}

\begin{frame}{Model 2: Deep Learning (CNN) on Spectrograms}
  \framesubtitle{Overview of our CNN Architecture (AUC $\sim$ 0.72)}
  \begin{center}
  \includegraphics*[scale=0.175]{img/cnn_arch.png}
  \end{center}
\end{frame}



\begin{frame}{Model 2: Deep Learning (CNN) on Spectrograms}
  \framesubtitle{Network fine tuning...}

  \begin{block}<1,4>{Data Imbalance}
    \begin{itemize}
    \item \textbf{Data Augmentation:} Added more augmented data/even repetition.
    \item \textbf{Bagging:} Train models with \textbf{5 bags} and average out.
    \end{itemize}
  \end{block}
  
  \begin{block}<2,4>{Missing Data}
    \textbf{Data Augmentation:} Augmented white patches on more data. Let
    network handle bad data.
  \end{block}
 
  \begin{block}<3,4>{Are we over-fitting yet?}
    \begin{itemize}

\item     \textbf{Early Stopping:} Stop training if validation accuracy isn't
    changing.
    \item \textbf{Folding:} Trained models using \textbf{5-Fold Cross Validation} and
    averaged them out.
    \item \textbf{Dropout:} Regularization to prevent over-fitting.
    \end{itemize}
  \end{block}
\end{frame}


\begin{frame}{Model 2: Deep Learning (CNN) on Spectrograms}
  \framesubtitle{Dropout: An effective technique to prevent over-fitting...}

  \begin{center}
  \includegraphics[scale=0.42]{img/dropout.png}
  \end{center}

\end{frame}



\begin{frame}{Model 3: SVM Classification on Radon Transforms}
  \framesubtitle{}

  \begin{center}
  \includegraphics[scale=0.38]{img/radon.png}

  Ref: https://arxiv.org/pdf/1604.04675.pdf (Page 3)
  \end{center}

\end{frame}


\begin{frame}{Model 3: SVM Classification on Radon Transforms}
  \framesubtitle{Motivation behind using Radon Transform...}

  \begin{block}{Why Radon Transform?}
    \begin{itemize}
  \item It is my research topic...so, I could not resist!
  \item It has been successful in recognition of speaker from sound
    signals~\cite{ajmera_text-independent_2011-2}.

  \item Well known/established in medical fields (basis of CT Scans, Tomography)

  \item Can provide with interesting robust features which are interpret-able as well.
    \end{itemize}
  \end{block}

\end{frame}


\begin{frame}{Model 3: SVM Classification on Radon Transforms}
  \framesubtitle{SVM with Radon Features AUC $\sim$ 0.65}

  \begin{block}{Input}
    Radon projections from stitched Spectrogram using \textbf{8} equidistant angles.
  \end{block}

  \begin{columns}
    \column{0.4\textwidth}

    \begin{center}
  \includegraphics*[scale=0.1]{img/radon_feats.jpg}
    \end{center}

  \column{0.6\textwidth}
  \begin{itemize}
    \item Projection from each $8$ of the angles are concatenated into one vector.
    \item Vector length: $\sqrt{(6 \times 16)^2 + 10^2} \times 8 = 776$.
    \item Can run PCA to further reduce dimensions to around $512$.
    \item Use \textbf{SVM} to classify using 5-Folds Cross Validation and 5 Bags
      averaging model (AUC $\sim$ 0.65).
  \end{itemize}
  \end{columns}


\end{frame}

\begin{frame}{Model 3: SVM Classification on Radon Transforms}
  \framesubtitle{TSNE Visualization of Radon Projections}

  \begin{center}
    \vspace*{-0.15cm}
  \includegraphics[scale=0.4]{img/tsne_Radon.eps}
  \end{center}

\end{frame}


\begin{frame}{Classification}
  \framesubtitle{Current best score on Kaggle...}

  \textbf{Ensemble} of 3 different classifier models:
  
  \begin{enumerate}
  \item \textbf{SVM/RF/GB} classification using various \textbf{DSP features}
  \item \textbf{Deep Learning:} CNN classification of Spectrograms
  \item SVM classification on \textbf{Radon Transforms} of Spectrograms
  \end{enumerate}

  \begin{block}{Current Kaggle Score}
    $\sim 0.74$
  \end{block}

\end{frame}

\begin{frame}{Finals Scores}
  \begin{center}
  \includegraphics[scale=0.36]{img/final_scores.eps}
  \end{center}

\end{frame}


\begin{frame}{Thanks}
 
  \begin{center}
  \includegraphics[scale=0.25]{img/logos.png}
  \end{center}

\end{frame}


\bibliography{ref}
\bibliographystyle{ieeetr}

\end{document}

